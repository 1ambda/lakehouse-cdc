parallelism=1
checkpoint.interval=10000
application.source.table=raw_customers
application.source.sql=\
CREATE TABLE raw_customers (\n\
    origin_ts TIMESTAMP(3) METADATA FROM 'value.ingestion-timestamp' VIRTUAL,\n\
    event_time TIMESTAMP(3) METADATA FROM 'value.source.timestamp' VIRTUAL,\n\
    origin_database STRING METADATA FROM 'value.source.database' VIRTUAL,\n\
    origin_schema STRING METADATA FROM 'value.source.schema' VIRTUAL,\n\
    origin_table STRING METADATA FROM 'value.source.table' VIRTUAL,\n\
    origin_properties MAP<STRING, STRING> METADATA FROM 'value.source.properties' VIRTUAL,\n\
    id BIGINT,\n\
    name STRING,\n\
    description STRING,\n\
    weight DECIMAL(38, 10)\n\
) WITH (\n\
    'connector'='kafka',\n\
    'topic'='cdc.local.inventory.customers',\n\
    'properties.bootstrap.servers'='localhost:9092',\n\
    'properties.group.id'='testGroup',\n\
    'properties.auto.offset.reset'='earliest',\n\
    'scan.startup.mode'='earliest-offset',\n\
    'format'='debezium-json',\n\
    'debezium-json.schema-include'='true',\n\
    'debezium-json.ignore-parse-errors'='false'\n\
);
application.sink.table=aggr_customers
application.sink.sql=\
CREATE TABLE aggr_customers (\n\
    id BIGINT,\n\
    weight DECIMAL(38, 10),\n\
    PRIMARY KEY (id) NOT ENFORCED\n\
) WITH (\n\
    'connector'='upsert-kafka',\n\
    'topic'='aggregation.customers',\n\
    'properties.bootstrap.servers'='localhost:9092',\n\
    'properties.allow.auto.create.topics'='true',\n\
    'value.format'='json',\n\
    'key.format'='json'\n\
);
application.apply.sql=\
INSERT INTO aggr_customers SELECT id, weight FROM raw_customers